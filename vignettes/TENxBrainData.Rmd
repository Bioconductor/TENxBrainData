---
title: "Authoring R Markdown vignettes"
author:
- name: Aaron Lun
  affiliation: Cancer Research UK Cambridge Institute, Cambridge, UK
- name: Martin Morgan
  affiliation: Roswell Park Cancer Institute, Buffalo, NY
output:
  BiocStyle::html_document:
    toc_float: true
package: TENxBrainData
vignette: |
  %\VignetteIndexEntry{Exploring the 1.3 million brain cell scRNA-seq data from 10X Genomics}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, echo=FALSE, results="hide", message=FALSE}
require(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
```

```{r style, echo=FALSE, results='asis'}
BiocStyle::markdown()
```

# Exploring the 1.3 million brain cell scRNA-seq data from 10X Genomics
Package: `r Biocpkg("TENxBrainData")` <br />
Author: Aaron Lun (alun@wehi.edu.au) <br />
Compilation date: `r Sys.Date()`

# Introduction

The `r Biocpkg("TENxBrainData")` package provides a _R_ /
_Bioconductor_ resource for representing and manipulating the 1.3
million brain cell single-cell RNA-seq (scRNA-seq) data set generated
by [10X Genomics][tenx].  It makes extensive use of the `r
Biocpkg("HDF5Array")` package to avoid loading the entire data set in
memory, instead storing the counts on disk as a HDF5 file and loading
subsets of the data into memory upon request.

# Loading in the data

We use the `TENxBrainData` function to download the relevant files
from Bioconductor's ExperimentHub web resource.  This includes the
HDF5 file containing the counts, as well as the metadata on the rows
(genes) and columns (cells).  The output is a single
`SingleCellExperiment` object from the `r
Biocpkg("SingleCellExperiment")` package.  This is equivalent to a
`SummarizedExperiment` class but with a number of features specific to
single-cell data.


```{r}
library(TENxBrainData)
tenx <- TENxBrainData()
tenx
```

The first call to this function will take some time due to the need to
download some moderately large files.  The files are then stored
locally such that ensuing calls in the same or new sessions are very
fast.

```{r}
TENxBrainData() # cheap
```

The count matrix itself is represented as a `DelayedMatrix` from the
`r Biocpkg("DelayedArray")` package.  This wraps the underlying HDF5
file in a container that can be manipulated in R.  Each count
represents the number of unique molecular identifiers (UMIs) assigned
to a particular gene in a particular cell.

```{r}
counts(tenx)
```

# Exploring the data

To quickly explore the data set, we compute some summary statistics on
the count matrix.  We increase the `r Biocpkg("DelayedArray")` block
size to indicate that we can use up to 2 GB of memory for loading the
data into memory from disk.

```{r}
options(DelayedArray.block.size=2e9)
```

We are interested in library sizes `colSums(counts(tenx))`, number of
genes expressed per cell `colSums(counts(tenx) != 0)`, and average
expression across cells `rowMeans(counts(tenx)). A naive implement
might be

```{r, eval = FALSE}
lib.sizes <- colSums(counts(tenx))
n.exprs <- colSums(counts(tenx) != 0L)
ave.exprs <- rowMeans(counts(tenx))
```

However, the data is read from disk, disk access is comparatively
slow, and the naive implementation reads the data three
times. Instead, we'll divide the data into column 'chunks' of about
10,000 cells

```{r}
chunksize <- 10000
cidx <- snow::splitIndices(ncol(tenx), ncol(tenx) / chunksize)
```

and iterate through the file reading the data and accumulating
statistics on each iteration. Since the operation is expensive, we
check first to see whether a cached (saved) version exists.

```{r}
library(BiocFileCache)
cached <- nrow(bfcquery(query="TENxBrainData/SCE")) == 1L
if (cached) {
    path <- bfcrpath(rnames="TENxBrainData/SCE")
    tenx <- readRDS(path)
}
```

If there is no cached version, we generate the object (this takes a
long time, e.g., 30 minutes).

```{r}
if (!cached) {
    lib.sizes <- n.exprs <- numeric(ncol(tenx))
    tot.exprs <- numeric(nrow(tenx))
    for (i in cidx) {
        message(".", appendLF=FALSE)
        m <- as.matrix(counts(tenx)[,i, drop=FALSE])
        lib.sizes[i] <- colSums(m)
        n.exprs[i] <- colSums(m != 0)
        tot.exprs <- tot.exprs + rowSums(m)
        }
    ave.exprs <- tot.exprs / ncol(tenx)
}
```

Since the calculations are expensive and might be useful in the
future, we annotate the `tenx` object

```{r}
if (!cached) {
    colData(tenx)$lib.sizes <- lib.sizes
    colData(tenx)$n.exprs <- n.exprs
    rowData(tenx)$ave.exprs <- ave.exprs
}
```

Library sizes follow an approximately log normal distribution, and are
surprisingly small.

```{r}
hist(
    log10(colData(tenx)$lib.sizes),
    xlab=expression(Log[10] ~ "Library size"),
    col="grey80"
)
```

Expression of only a few thousand genes are detected in each sample.

```{r}
hist(colData(tenx)$n.exprs, xlab="Number of detected genes", col="grey80")
```

Average expression values (read counts) are small.

```{r}
hist(
    log10(rowData(tenx)$ave.exprs),
    xlab=expression(Log[10] ~ "Average count"),
    col="grey80"
)
```

We also examine the top most highly-expressing genes in this data set.

```{r}
o <- order(rowData(tenx)$ave.exprs, decreasing=TRUE)
head(rowData(tenx)[o,])
```

More advanced analysis procedures are implemented in various
_Bioconductor_ packages - see the `SingleCell` biocViews for more
details.

Here we save the _SingleCellExperiment_ object, for later use. The
object is saved using the base _R_ function `saveRDS()`; the large
data are _not_ duplicated, but the saved object is only valid as long
as the original path

```{r}
if (!cached) {
    path <- bfcnew(rname = "TENxBrainData/SCE", ext="rds")
    saveRDS(tenx, path)
}
```

# Session information

```{r}
sessionInfo()
```

[tenx]: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons
